model_config:
  number_ts: 264
  embedding_dim: 512
  ### add hear n_heads ### 
  n_blocks: 12
  #dropout: 0.5
  pool_size: 4
  number_of_heads: 4

trainer_config:
  save_every: 1
  max_epochs: 5
  snapshot_name: "small_model"
  snapshot_dir: "/model"
  compile_model: True
  use_wnb: False

  
  
optimizer_config:
  lr: 0.000001
  weight_decay: 0.00001
  momentum: 0.99

scheduler_config:
  T_max: 15

data:
  train_path:
   file: "data/array_train.dat"
   length_file: "data/lengthsarray_train.dat"
   file_names: "data/names_array_train.txt"
   lags: 512 # 512 -> 1 prediction, we will do
  val_path:
   file: "data/array_test.dat"
   length_file: "data/lengthsarray_test.dat"
   file_names: "data/names_array_test.txt"
   lags: 512 # 512 -> 1 prediction, we will do

  
  train_data_details:
   batch_size: 256
   num_workers: 4
 #  shuffle: True
   pin_memory: True
   persistent_workers: True
   prefetch_factor: 2

  val_data_details:
   batch_size: 256
   num_workers: 4
#   shuffle: False
   pin_memory: True
   drop_last: True
   
   
   
  

